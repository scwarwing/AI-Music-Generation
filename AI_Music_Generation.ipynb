{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Music Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMt9Oj51z6UhHiIQg7DbhSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scwarwing/AI-Music-Generation/blob/master/AI_Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6N1YA77QkRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import numpy\n",
        "import keras\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOrElbeYQux9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounting drive\n",
        "# This will require authentication : Follow the steps as guided\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f3ZrIq2R0-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ3wBXILSmUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network():\n",
        "    \n",
        "    \"\"\" This function calls all other functions and trains the LSTM\"\"\"\n",
        "    \n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "    model.summary()\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoYA25rLRHD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_notes():\n",
        "  notes = []\n",
        "  for file in glob.glob(r\"/content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/*.mid\"):\n",
        "    midi = converter.parse(file)\n",
        "    print(\"Parsing %s\" % file)\n",
        "    notes_to_parse = None\n",
        "\n",
        "    try: # file has instrument parts\n",
        "      s2 = instrument.partitionByInstrument(midi)\n",
        "      notes_to_parse = s2.parts[0].recurse() \n",
        "\n",
        "    except: # file has notes in a flat structure\n",
        "      notes_to_parse = midi.flat.notes\n",
        "\n",
        "    for element in notes_to_parse:\n",
        "      if isinstance(element, note.Note):\n",
        "        notes.append(str(element.pitch))\n",
        "      elif isinstance(element, chord.Chord):\n",
        "        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "  return notes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu7eyW5XRRY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \n",
        "    \"\"\" Prepare the sequences which are the inputs for the LSTM \"\"\"\n",
        "    \n",
        "    # sequence length should be changed after experimenting with different numbers\n",
        "    sequence_length = 10\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMVt8RbjRVUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \n",
        "    \"\"\" Creates the structure of the neural network \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dQXwIVbSe-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, network_input, network_output):\n",
        "    \n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    \n",
        "    filepath = \"/content/data/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    # experiment with different epoch sizes and batch sizes\n",
        "    model.fit(network_input, network_output, epochs=100, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io-TzJreShWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51733e1e-cd35-44a4-b63a-86efc747454a"
      },
      "source": [
        "train_network()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Lonely Together - Avicii, Rita Ora.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/You Make Me.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/SOS.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Fade Into Darkness.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/The Nights.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/The Days.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Sunshine.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Addicted To You.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Broken Arrows.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/For A Better Day.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Without You.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Wake Me Up.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Rapture.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Silhouettes.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Seek Bromance.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/I Could Be The One.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Trouble.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Waiting For Love.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Levels.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Hey Brother - Avicii.mid\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 10, 512)           1052672   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 10, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 190)               48830     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 190)               0         \n",
            "=================================================================\n",
            "Total params: 5,431,230\n",
            "Trainable params: 5,431,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.2149\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1494\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1428\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1392\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1349\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1341\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1333\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 9s 27ms/step - loss: 4.1321\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 9s 26ms/step - loss: 4.1312\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 8s 26ms/step - loss: 4.1273\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1244\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1169\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.1025\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.0705\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.0516\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.0389\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.0276\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.0186\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 4.0015\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.9679\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.9367\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.9114\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.8881\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.8698\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.8478\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.8173\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.8009\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.7629\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.7240\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.6688\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.6317\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.5819\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.5159\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.4490\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.3877\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.2981\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.2251\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.1100\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 3.0000\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 2.8439\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 2.7164\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 2.5646\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 2.4017\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 2.2411\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 9s 27ms/step - loss: 2.0525\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 9s 26ms/step - loss: 1.9164\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 1.7501\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 1.5781\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 1.4558\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 1.3231\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 1.1898\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 1.0829\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.9824\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.9014\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.7987\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.7281\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.6691\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.6222\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.5784\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.5253\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.4871\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.4659\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.4355\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.4189\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.4063\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3882\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3693\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3549\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3646\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3399\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3211\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3234\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2943\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2797\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.3039\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2907\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2819\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2826\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2590\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2609\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2698\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 9s 26ms/step - loss: 0.2421\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 9s 26ms/step - loss: 0.2737\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2340\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2260\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2278\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2298\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2644\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2213\n",
            "Epoch 90/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2195\n",
            "Epoch 91/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2031\n",
            "Epoch 92/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2096\n",
            "Epoch 93/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2118\n",
            "Epoch 94/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2055\n",
            "Epoch 95/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2122\n",
            "Epoch 96/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.2117\n",
            "Epoch 97/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.1882\n",
            "Epoch 98/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.1968\n",
            "Epoch 99/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.1886\n",
            "Epoch 100/100\n",
            "331/331 [==============================] - 8s 25ms/step - loss: 0.1794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xijk7fn3Sisv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate():\n",
        "    \"\"\" Generates the midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open('/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ALoKfNnAi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(r'/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'rb') as filepath:\n",
        "  notes = pickle.load(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTBO1l4upnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "    \n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    \n",
        "    # map back from integers to notes\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 10\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP98nNS6urhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \n",
        "    \"\"\" Creates the structure of the neural network \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights('/content/data/weights-improvement-65-0.3733-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLVSGLHGu8yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    \n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction) # numpy array of predictions\n",
        "        result = int_to_note[index] # indexing the note with the highest probability\n",
        "        prediction_output.append(result) # that note is the prediction output\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UJZQE5DvBvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_midi(prediction_output):\n",
        "    \n",
        "    \"\"\" Converts the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.SnareDrum()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.SnareDrum()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9koxs5xWvGBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-eRlC9vIFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'rb') as filepath:\n",
        "  notes = pickle.load(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFisUpJVbL1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
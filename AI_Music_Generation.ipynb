{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Music Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMt9Oj51z6UhHiIQg7DbhSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scwarwing/AI-Music-Generation/blob/master/AI_Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6N1YA77QkRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2739b2b4-cf69-49b9-fbe5-fc1f1651e4df"
      },
      "source": [
        "import glob\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import numpy\n",
        "import keras\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOrElbeYQux9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ef5074cd-7a23-4e8d-f803-0621ac592f3c"
      },
      "source": [
        "# Mounting drive\n",
        "# This will require authentication : Follow the steps as guided\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f3ZrIq2R0-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7414b31d-1b3b-438a-889b-50bb297e571e"
      },
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'AI Music Generation'  'AI Music Generation.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ3wBXILSmUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network():\n",
        "    \n",
        "    \"\"\" This function calls all other functions and trains the LSTM\"\"\"\n",
        "    \n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "    model.summary()\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoYA25rLRHD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_notes():\n",
        "  notes = []\n",
        "  for file in glob.glob(r\"/content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/*.mid\"):\n",
        "    midi = converter.parse(file)\n",
        "    print(\"Parsing %s\" % file)\n",
        "    notes_to_parse = None\n",
        "\n",
        "    try: # file has instrument parts\n",
        "      s2 = instrument.partitionByInstrument(midi)\n",
        "      notes_to_parse = s2.parts[0].recurse() \n",
        "\n",
        "    except: # file has notes in a flat structure\n",
        "      notes_to_parse = midi.flat.notes\n",
        "\n",
        "    for element in notes_to_parse:\n",
        "      if isinstance(element, note.Note):\n",
        "        notes.append(str(element.pitch))\n",
        "      elif isinstance(element, chord.Chord):\n",
        "        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "\n",
        "  return notes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu7eyW5XRRY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \n",
        "    \"\"\" Prepare the sequences which are the inputs for the LSTM \"\"\"\n",
        "    \n",
        "    # sequence length should be changed after experimenting with different numbers\n",
        "    sequence_length = 10\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMVt8RbjRVUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \n",
        "    \"\"\" Creates the structure of the neural network \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dQXwIVbSe-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, network_input, network_output):\n",
        "    \n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    \n",
        "    filepath = \"/content/data/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    # experiment with different epoch sizes and batch sizes\n",
        "    model.fit(network_input, network_output, epochs=100, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io-TzJreShWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14665f49-94d4-4c65-f597-bcfa38bfa8f2"
      },
      "source": [
        "train_network()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Lonely Together - Avicii, Rita Ora.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/You Make Me.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/SOS.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Fade Into Darkness.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/The Nights.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/The Days.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Sunshine.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Addicted To You.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Broken Arrows.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/For A Better Day.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Without You.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Wake Me Up.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Rapture.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Silhouettes.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Seek Bromance.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/I Could Be The One.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Trouble.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Waiting For Love.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Levels.mid\n",
            "Parsing /content/drive/My Drive/Colab Notebooks/AI Music Generation/midi files/Hey Brother - Avicii.mid\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 10, 512)           1052672   \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 10, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_21 (LSTM)               (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 190)               48830     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 190)               0         \n",
            "=================================================================\n",
            "Total params: 5,431,230\n",
            "Trainable params: 5,431,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "21146/21146 [==============================] - 17s 810us/step - loss: 4.2186\n",
            "Epoch 2/100\n",
            "21146/21146 [==============================] - 17s 781us/step - loss: 4.1531\n",
            "Epoch 3/100\n",
            "21146/21146 [==============================] - 16s 766us/step - loss: 4.1409\n",
            "Epoch 4/100\n",
            "21146/21146 [==============================] - 16s 771us/step - loss: 4.1379\n",
            "Epoch 5/100\n",
            "21146/21146 [==============================] - 16s 759us/step - loss: 4.1358\n",
            "Epoch 6/100\n",
            "21146/21146 [==============================] - 16s 768us/step - loss: 4.1339\n",
            "Epoch 7/100\n",
            "21146/21146 [==============================] - 17s 787us/step - loss: 4.1311\n",
            "Epoch 8/100\n",
            "21146/21146 [==============================] - 16s 765us/step - loss: 4.1267\n",
            "Epoch 9/100\n",
            "21146/21146 [==============================] - 16s 769us/step - loss: 4.1240\n",
            "Epoch 10/100\n",
            "21146/21146 [==============================] - 16s 761us/step - loss: 4.1079\n",
            "Epoch 11/100\n",
            "21146/21146 [==============================] - 16s 763us/step - loss: 4.0834\n",
            "Epoch 12/100\n",
            "21146/21146 [==============================] - 16s 758us/step - loss: 4.0611\n",
            "Epoch 13/100\n",
            "21146/21146 [==============================] - 16s 761us/step - loss: 4.0457\n",
            "Epoch 14/100\n",
            "21146/21146 [==============================] - 16s 769us/step - loss: 4.0332\n",
            "Epoch 15/100\n",
            "21146/21146 [==============================] - 16s 768us/step - loss: 4.0168\n",
            "Epoch 16/100\n",
            "21146/21146 [==============================] - 16s 768us/step - loss: 3.9790\n",
            "Epoch 17/100\n",
            "21146/21146 [==============================] - 16s 755us/step - loss: 3.9416\n",
            "Epoch 18/100\n",
            "21146/21146 [==============================] - 16s 755us/step - loss: 3.9242\n",
            "Epoch 19/100\n",
            "21146/21146 [==============================] - 16s 760us/step - loss: 3.9055\n",
            "Epoch 20/100\n",
            "21146/21146 [==============================] - 16s 759us/step - loss: 3.8796\n",
            "Epoch 21/100\n",
            "21146/21146 [==============================] - 16s 766us/step - loss: 3.8545\n",
            "Epoch 22/100\n",
            "21146/21146 [==============================] - 16s 753us/step - loss: 3.8334\n",
            "Epoch 23/100\n",
            "21146/21146 [==============================] - 16s 761us/step - loss: 3.8026\n",
            "Epoch 24/100\n",
            "21146/21146 [==============================] - 16s 745us/step - loss: 3.7685\n",
            "Epoch 25/100\n",
            "21146/21146 [==============================] - 16s 755us/step - loss: 3.7317\n",
            "Epoch 26/100\n",
            "21146/21146 [==============================] - 17s 784us/step - loss: 3.6738\n",
            "Epoch 27/100\n",
            "21146/21146 [==============================] - 16s 757us/step - loss: 3.6286\n",
            "Epoch 28/100\n",
            "21146/21146 [==============================] - 16s 749us/step - loss: 3.5740\n",
            "Epoch 29/100\n",
            "21146/21146 [==============================] - 16s 757us/step - loss: 3.5183\n",
            "Epoch 30/100\n",
            "21146/21146 [==============================] - 16s 759us/step - loss: 3.4457\n",
            "Epoch 31/100\n",
            "21146/21146 [==============================] - 16s 760us/step - loss: 3.3766\n",
            "Epoch 32/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 3.2960\n",
            "Epoch 33/100\n",
            "21146/21146 [==============================] - 16s 752us/step - loss: 3.2084\n",
            "Epoch 34/100\n",
            "21146/21146 [==============================] - 16s 749us/step - loss: 3.1169\n",
            "Epoch 35/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 3.0000\n",
            "Epoch 36/100\n",
            "21146/21146 [==============================] - 16s 753us/step - loss: 2.8739\n",
            "Epoch 37/100\n",
            "21146/21146 [==============================] - 16s 748us/step - loss: 2.7369\n",
            "Epoch 38/100\n",
            "21146/21146 [==============================] - 16s 753us/step - loss: 2.5931\n",
            "Epoch 39/100\n",
            "21146/21146 [==============================] - 16s 750us/step - loss: 2.4422\n",
            "Epoch 40/100\n",
            "21146/21146 [==============================] - 16s 763us/step - loss: 2.2865\n",
            "Epoch 41/100\n",
            "21146/21146 [==============================] - 16s 752us/step - loss: 2.1335\n",
            "Epoch 42/100\n",
            "21146/21146 [==============================] - 16s 755us/step - loss: 1.9727\n",
            "Epoch 43/100\n",
            "21146/21146 [==============================] - 16s 755us/step - loss: 1.8171\n",
            "Epoch 44/100\n",
            "21146/21146 [==============================] - 16s 750us/step - loss: 1.6691\n",
            "Epoch 45/100\n",
            "21146/21146 [==============================] - 16s 769us/step - loss: 1.5446\n",
            "Epoch 46/100\n",
            "21146/21146 [==============================] - 16s 764us/step - loss: 1.3884\n",
            "Epoch 47/100\n",
            "21146/21146 [==============================] - 16s 752us/step - loss: 1.3064\n",
            "Epoch 48/100\n",
            "21146/21146 [==============================] - 16s 753us/step - loss: 1.1793\n",
            "Epoch 49/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 1.0633\n",
            "Epoch 50/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 0.9783\n",
            "Epoch 51/100\n",
            "21146/21146 [==============================] - 16s 750us/step - loss: 0.9145\n",
            "Epoch 52/100\n",
            "21146/21146 [==============================] - 16s 753us/step - loss: 0.8323\n",
            "Epoch 53/100\n",
            "21146/21146 [==============================] - 16s 750us/step - loss: 0.7641\n",
            "Epoch 54/100\n",
            "21146/21146 [==============================] - 16s 753us/step - loss: 0.6907\n",
            "Epoch 55/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 0.6563\n",
            "Epoch 56/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 0.6076\n",
            "Epoch 57/100\n",
            "21146/21146 [==============================] - 16s 754us/step - loss: 0.5510\n",
            "Epoch 58/100\n",
            "21146/21146 [==============================] - 16s 749us/step - loss: 0.5250\n",
            "Epoch 59/100\n",
            "21146/21146 [==============================] - 16s 762us/step - loss: 0.4966\n",
            "Epoch 60/100\n",
            "21146/21146 [==============================] - 16s 761us/step - loss: 0.4660\n",
            "Epoch 61/100\n",
            "21146/21146 [==============================] - 16s 757us/step - loss: 0.4540\n",
            "Epoch 62/100\n",
            "21146/21146 [==============================] - 16s 746us/step - loss: 0.4453\n",
            "Epoch 63/100\n",
            "21146/21146 [==============================] - 16s 749us/step - loss: 0.4116\n",
            "Epoch 64/100\n",
            "21146/21146 [==============================] - 16s 757us/step - loss: 0.3965\n",
            "Epoch 65/100\n",
            "21146/21146 [==============================] - 16s 773us/step - loss: 0.3733\n",
            "Epoch 66/100\n",
            "21146/21146 [==============================] - 16s 752us/step - loss: 0.3455\n",
            "Epoch 67/100\n",
            "10176/21146 [=============>................] - ETA: 8s - loss: 0.3023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6fd1a7e30b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-3925ce54356f>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-cd452bcb4b8a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, network_input, network_output)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# experiment with different epoch sizes and batch sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xijk7fn3Sisv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate():\n",
        "    \"\"\" Generates the midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open('/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14ALoKfNnAi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(r'/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'rb') as filepath:\n",
        "  notes = pickle.load(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTBO1l4upnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "    \n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    \n",
        "    # map back from integers to notes\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 10\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP98nNS6urhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \n",
        "    \"\"\" Creates the structure of the neural network \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights('/content/data/weights-improvement-65-0.3733-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLVSGLHGu8yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    \n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction) # numpy array of predictions\n",
        "        result = int_to_note[index] # indexing the note with the highest probability\n",
        "        prediction_output.append(result) # that note is the prediction output\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UJZQE5DvBvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_midi(prediction_output):\n",
        "    \n",
        "    \"\"\" Converts the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.SnareDrum()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.SnareDrum()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "    midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9koxs5xWvGBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-eRlC9vIFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/AI Music Generation/data/notes', 'rb') as filepath:\n",
        "  notes = pickle.load(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFisUpJVbL1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}